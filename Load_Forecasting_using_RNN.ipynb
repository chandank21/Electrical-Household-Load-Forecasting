{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Load Forecasting using RNN.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/chandank21/Electrical-Household-Load-Forecasting/blob/main/Load_Forecasting_using_RNN.ipynb",
      "authorship_tag": "ABX9TyM9TAQnLgpG6OtdnY53xpbm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandank21/Electrical-Household-Load-Forecasting/blob/main/Load_Forecasting_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YZPDbYx28-yS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from  sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y1eKVCWk9jhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a906bd40-1278-4eaf-961b-9500d2a6bfc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_dir):\n",
        "    data = pd.read_csv(file_dir,sep=';',\n",
        "                    header=0,low_memory=False,\n",
        "                    infer_datetime_format=True,\n",
        "                    parse_dates={'datetime':[0,1]},\n",
        "                    index_col=['datetime'])\n",
        "    return data\n",
        "def clean_data(data):\n",
        "  data.replace('?',np.NaN,inplace=True)\n",
        "  data.fillna(method='bfill')\n",
        "  data = data.astype('float32')\n",
        "  return data\n",
        "def scaling_data(data):\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  scaled = scaler.fit_transform(data)\n",
        "  return scaled\n",
        "\n",
        "def series_to_supervised(df_as_np,n_lags,n_out=1):\n",
        "  X,y = [],[]\n",
        "  for i in range(len(df_as_np)-n_lags):\n",
        "    row = [ a for a in df_as_np[i:i+n_lags]]\n",
        "    X.append(row)\n",
        "    label = df_as_np[i+n_lags:i+n_lags+n_out][0]\n",
        "    y.append(label)\n",
        "  return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "aRMRMtHcJkCJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_data(r'/content/drive/MyDrive/datasets/household_power_consumption.txt')"
      ],
      "metadata": {
        "id": "1HMr57h5JoyB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols=['Global_active_power', 'Global_reactive_power', 'Global_intensity']\n",
        "dataset= dataset[cols]\n",
        "dataset = clean_data(dataset)\n",
        "dataset = dataset.resample('H').mean()\n",
        "dataset = scaling_data(dataset)\n",
        "n_lags=12\n",
        "n_out=1\n",
        "input,target = series_to_supervised(dataset.values,n_lags,n_out)\n",
        "\n",
        "train_input = input[:23000]\n",
        "test_input = input[26000:]\n",
        "validation_input = input[23000:26000]\n",
        "train_target = target[:23000]\n",
        "test_target = target[26000:]\n",
        "validation_target = target[23000:26000]\n",
        "train_input.shape,test_input.shape,train_target.shape,test_target.shape"
      ],
      "metadata": {
        "id": "_5DiBFerKCJ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "58fe5fc7-2b21-4ee6-dbc7-e1426fa4d18d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-71b57dd3707b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Global_active_power'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Global_reactive_power'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Global_intensity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'H'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "2W95a-zeYaZj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#date_index=new_data.index.to_series()\n",
        "#new_data['year']=date_index.dt.year\n",
        "#new_data['month']=date_index.dt.month\n",
        "#new_data['day_of_week']=date_index.dt.dayofweek\n",
        "#new_data['hour']=date_index.dt.hour\n",
        "#new_data = new_data.reset_index(drop=True)\n",
        "\n",
        "#new_data['hour_cos'] = np.cos(2 * np.pi * new_data['hour'] / 24)\n",
        "#new_data['hour_sin'] = np.sin(2 * np.pi * new_data['hour'] / 24)\n",
        "\n",
        "#new_data['Global_active_power'] = 1000*new_data['Global_active_power']\n",
        "\n",
        "#new_data.drop(labels=['hour'],axis=1,inplace=True)\n",
        "#new_data.drop(labels=['Global_active_power'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "_8b80pJwL4SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models..."
      ],
      "metadata": {
        "id": "XuxFeoxtFE5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model1..LSTM**"
      ],
      "metadata": {
        "id": "FEwUU8RHFOf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(InputLayer((200, 5)))\n",
        "model1.add(LSTM(100))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(8, 'relu'))\n",
        "model1.add(Dense(1, 'linear'))\n",
        "\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "J3pw4zntN5LJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4700f33-f14e-4475-85b0-90aff60d842b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 64)                17920     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 520       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,449\n",
            "Trainable params: 18,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp1 = ModelCheckpoint('model1/', save_best_only=True)\n",
        "\n",
        "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0005), metrics=RootMeanSquaredError())\n",
        "\n",
        "model_summary = model1.fit(train_input, train_target, validation_data=(validation_input, validation_target), epochs=50, batch_size=70, callbacks=[cp1])"
      ],
      "metadata": {
        "id": "nz9iWhqzOCaQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(model_summary.history['loss'])\n",
        "plt.plot(model_summary.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mgAsWTDWWbjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model1 = load_model('model1/')"
      ],
      "metadata": {
        "id": "H-pbYDV8QrPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predicted = model1.predict(train_input).flatten()\n",
        "train_results = pd.DataFrame(data={'train_predicted':train_predicted, 'train_target':train_target.flatten()})"
      ],
      "metadata": {
        "id": "xJMQLb6-QrTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_results['train_predicted'][50:100])\n",
        "plt.plot(train_results['train_target'][50:100])"
      ],
      "metadata": {
        "id": "ddLy4ofeSumw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model1.predict(test_input).flatten()\n",
        "test_results = pd.DataFrame(data={'test_predictions':test_predictions, 'test_target':test_target.flatten(),'error':test_target.flatten()-test_predictions})\n",
        "test_results"
      ],
      "metadata": {
        "id": "SNiIZtPtdyiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "AfkUOfdPedL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_percentage_error(train_results.train_predicted,train_results.train_target)"
      ],
      "metadata": {
        "id": "rILFZ9i6edOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_percentage_error(test_results.test_predictions,test_results.test_target)"
      ],
      "metadata": {
        "id": "ax6RgIPcfBDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL2..Conv1D**"
      ],
      "metadata": {
        "id": "Eay7SjG1g4Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(InputLayer((100, 1)))\n",
        "model2.add(Conv1D(64, kernel_size=2))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(8, 'relu'))\n",
        "model2.add(Dense(1, 'linear'))\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "iI9HVprjg95i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp2 = ModelCheckpoint('model2/', save_best_only=True)\n",
        "model2.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])"
      ],
      "metadata": {
        "id": "dshHolXNhXj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(train_input, train_target, validation_data=(validation_input, validation_target), epochs=10, callbacks=[cp2])"
      ],
      "metadata": {
        "id": "q8Q36cteEYXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model2 = load_model('model2/')"
      ],
      "metadata": {
        "id": "wu0zLVSREYdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predicted = model2.predict(train_input).flatten()\n",
        "train_results = pd.DataFrame(data={'train_predicted':train_predicted, 'train_target':train_target.flatten()})"
      ],
      "metadata": {
        "id": "R4lBFUSyEYhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model2.predict(test_input).flatten()\n",
        "test_results = pd.DataFrame(data={'test_predictions':test_predictions, 'test_target':test_target.flatten()})"
      ],
      "metadata": {
        "id": "YWnTatBuE7r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test error...\")\n",
        "mean_absolute_percentage_error(test_results.test_predictions,test_results.test_target)"
      ],
      "metadata": {
        "id": "kAq786zGEYkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Error....\")\n",
        "mean_absolute_percentage_error(train_results.train_predicted,train_results.train_target)"
      ],
      "metadata": {
        "id": "ObrUJtGAE3W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model3...GRU**"
      ],
      "metadata": {
        "id": "erN1DFG3Ffn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential()\n",
        "model3.add(InputLayer((100, 1)))\n",
        "model3.add(GRU(64))\n",
        "model3.add(Dense(8, 'relu'))\n",
        "model3.add(Dense(1, 'linear'))\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "LNSIxHID3l25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp3 = ModelCheckpoint('model3/', save_best_only=True)\n",
        "model3.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])"
      ],
      "metadata": {
        "id": "DXHNl4Us3l7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(train_input, train_target, validation_data=(validation_input, validation_target), epochs=10, callbacks=[cp3])"
      ],
      "metadata": {
        "id": "C1r2tSmI3l-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model3 = load_model('model3/')"
      ],
      "metadata": {
        "id": "yEJF9mW6HOI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predicted = model2.predict(train_input).flatten()\n",
        "train_results = pd.DataFrame(data={'train_predicted':train_predicted, 'train_target':train_target.flatten()})\n",
        "\n",
        "test_predictions = model2.predict(test_input).flatten()\n",
        "test_results = pd.DataFrame(data={'test_predictions':test_predictions, 'test_target':test_target.flatten()})"
      ],
      "metadata": {
        "id": "uFupoRGpHXFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test error...\")\n",
        "mean_squared_error(test_results.test_predictions,test_results.test_target)"
      ],
      "metadata": {
        "id": "e8ngA8KkHXIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Error....\")\n",
        "mean_squared_error(train_results.train_predicted,train_results.train_target)"
      ],
      "metadata": {
        "id": "pTVViyMQHXV3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}